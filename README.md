<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:0d1117,50:1a1b27,100:24283b&height=230&section=header&text=Derek%20J.%20Russell&fontSize=48&fontColor=70a5fd&fontAlignY=35&desc=AI%20Engineer%20%7C%20Computer%20Engineer%20%7C%20Autonomous%20Systems%20Architect&descSize=18&descColor=a9b1d6&descAlignY=55&animation=fadeIn" width="100%"/>

<br>

<img src="./assets/jarvis-ui.png" width="90%" alt="JARVIS Interface ‚Äî Autonomous AI Operating System"/>

<br>

[![Typing SVG](https://readme-typing-svg.demolab.com?font=JetBrains+Mono&weight=600&size=20&duration=3000&pause=1000&color=70A5FD&center=true&vCenter=true&multiline=true&repeat=true&width=820&height=80&lines=3%2C900%2B+commits+%C2%B7+2.5M+lines+of+code+%C2%B7+11+languages;Building+production-grade+autonomous+AI+infrastructure)](https://github.com/drussell23)

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/derek-j-russell/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/drussell23)
[![Featured](https://img.shields.io/badge/Mustang_News-Featured-8B0000?style=for-the-badge)](https://mustangnews.net/10-years-in-the-making-one-cal-poly-students-unique-path-to-an-engineering-degree/)
[![Profile Views](https://komarev.com/ghpvc/?username=drussell23&style=for-the-badge&color=1a1b27&label=PROFILE+VIEWS)](https://github.com/drussell23)

</div>

---

<div align="center">

> *I design, build, and deploy production-grade AI ecosystems from bare metal to cloud inference.*
> *My work sits at the intersection of systems engineering, machine learning infrastructure, and real-time intelligent automation.*

</div>

For the past 12 months, I have been executing a solo build of **JARVIS** ‚Äî a three-repository, multi-process autonomous AI operating system spanning Python, C++, Rust, Swift, Objective-C, and TypeScript. The system orchestrates 60+ asynchronous agents across a neural mesh, routes inference dynamically between local Apple Silicon and GCP, performs real-time voice biometric authentication, controls macOS at the native API level, and continuously trains its own models through a self-improving feedback loop.

---

## <img src="https://media.giphy.com/media/iY8CRBdQXODJSCERIr/giphy.gif" width="30"> Tech Stack

<div align="center">

#### Languages

[![Languages](https://skillicons.dev/icons?i=py,cpp,rust,swift,ts,js,bash,html,css&theme=dark)](https://skillicons.dev)

#### ML, Inference and Data

[![ML](https://skillicons.dev/icons?i=pytorch,tensorflow,opencv,sklearn,anaconda&theme=dark)](https://skillicons.dev)

#### Infrastructure and Cloud

[![Infra](https://skillicons.dev/icons?i=gcp,docker,kubernetes,terraform,redis,postgres,sqlite,nginx,cmake,githubactions&theme=dark)](https://skillicons.dev)

#### Backend and Frontend

[![Stack](https://skillicons.dev/icons?i=fastapi,react,nextjs,nodejs,vscode,git,github,linux,apple,md&theme=dark)](https://skillicons.dev)

</div>

<details>
<summary><b>Full Stack Inventory (text)</b></summary>
<br>

| Category | Technologies |
|----------|-------------|
| **Languages** | Python, C++, Rust, Swift, Objective-C, TypeScript, JavaScript, SQL, Shell/Bash, AppleScript, HTML/CSS, ARM64 Assembly |
| **ML / Inference** | PyTorch, Transformers, llama.cpp, llama-cpp-python, GGUF quantization, ONNX Runtime, CoreML Tools, SpeechBrain, scikit-learn, SentenceTransformers, HuggingFace Hub, safetensors, tiktoken, Numba (JIT), sympy, LangChain, YOLO |
| **Training** | LoRA, DPO, RLHF, FSDP, MAML (meta-learning), curriculum learning, federated learning, causal reasoning, world model training, online learning, active learning, EWC |
| **Models / Vision** | LLaVA (multimodal), ECAPA-TDNN (speaker verification), Whisper (faster-whisper, openai-whisper), Porcupine/Picovoice (wake word), Piper TTS, OmniParser (OCR) |
| **LLM APIs** | Anthropic Claude API (chat, vision, computer use), OpenAI API (chat completions, embeddings) |
| **Rust** | PyO3, ndarray, rayon, parking_lot, DashMap, crossbeam, serde, mimalloc, image crate, ARM64 SIMD |
| **Swift / macOS** | Swift Package Manager, CoreLocation, WeatherKit, AppKit, Foundation, Quartz/CoreGraphics, Accessibility API, AVFoundation, pyobjc, launchd, osascript, yabai |
| **Vector / Data** | ChromaDB, FAISS, Redis, PostgreSQL (asyncpg, psycopg2), SQLite (aiosqlite), NetworkX, bloom filters |
| **Infrastructure** | GCP (Compute Engine, Cloud SQL, Cloud Run, Secret Manager, Monitoring), Docker, docker-compose, Terraform, Kubernetes, systemd, CMake, pybind11, cpp-httplib |
| **CI/CD** | GitHub Actions (20+ workflows), git worktrees |
| **Backend** | FastAPI, uvicorn, uvloop, gRPC, Protobuf, asyncio, aiohttp, httpx, WebSocket, Cloud SQL Proxy, circuit breakers, exponential backoff, distributed locks, epoch fencing |
| **Observability** | OpenTelemetry (tracing + metrics + OTLP/gRPC export), structlog, psutil, Pydantic, JSONL telemetry pipeline |
| **Frontend** | React 19, Next.js, Framer Motion, Axios, WebSocket real-time streaming |
| **Audio / Vision** | OpenCV, sounddevice, PyAudio, webrtcvad (VAD), speexdsp (AEC), librosa, pyautogui |

</details>

---

## <img src="https://media.giphy.com/media/l0HlNaQ6gWfllcjDO/giphy.gif" width="30"> Demo

<div align="center">

<img src="./assets/jarvis-demo.gif" width="90%" alt="JARVIS Context Awareness Demo"/>

<br><br>

[![Watch Full Demo](https://img.shields.io/badge/Watch_Full_Demo-Context_Awareness-70a5fd?style=for-the-badge&logo=googlechrome&logoColor=white)](https://docs.google.com/videos/d/1inRKtPeCSqKbTvJfUnmulTkzJ4PX-HkqaIwWBpAUGdA/edit)

</div>

---

## <img src="https://media.giphy.com/media/W5eoZHPpUx9sapR0eu/giphy.gif" width="30"> GitHub Stats

<div align="center">

<a href="https://github.com/drussell23">
  <img height="180" src="https://github-readme-stats-sigma-five.vercel.app/api?username=drussell23&show_icons=true&theme=tokyonight&hide_border=true&bg_color=0d1117&title_color=70a5fd&icon_color=bf91f3&text_color=a9b1d6&count_private=true&include_all_commits=true" />
</a>
<a href="https://github.com/drussell23">
  <img height="180" src="https://github-readme-stats-sigma-five.vercel.app/api/top-langs/?username=drussell23&layout=compact&theme=tokyonight&hide_border=true&bg_color=0d1117&title_color=70a5fd&text_color=a9b1d6&langs_count=10" />
</a>

<br>

<a href="https://github.com/drussell23">
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=drussell23&theme=tokyonight&hide_border=true&background=0d1117&stroke=1a1b27&ring=70a5fd&fire=bf91f3&currStreakLabel=a9b1d6&sideLabels=a9b1d6&currStreakNum=70a5fd&sideNums=70a5fd&dates=545c7e" />
</a>

<br>

<a href="https://github.com/drussell23">
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=drussell23&bg_color=0d1117&color=a9b1d6&line=70a5fd&point=bf91f3&area=true&area_color=70a5fd&hide_border=true" width="95%"/>
</a>

</div>

<div align="center">

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/drussell23/drussell23/output/github-snake-dark.svg" />
  <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/drussell23/drussell23/output/github-snake.svg" />
  <img alt="github-snake" src="https://raw.githubusercontent.com/drussell23/drussell23/output/github-snake-dark.svg" width="100%" />
</picture>

</div>

<div align="center">

<a href="https://github.com/ryo-ma/github-profile-trophy">
  <img src="https://github-profile-trophy-tawny.vercel.app/?username=drussell23&theme=tokyonight&no-frame=true&no-bg=true&column=7&margin-w=10" width="95%"/>
</a>

</div>

---

## <img src="https://media.giphy.com/media/VgCDAzcKvsR6OM0uWg/giphy.gif" width="30"> The JARVIS Ecosystem

JARVIS is not a chatbot wrapper. It is a distributed AI operating system composed of three interdependent repositories ‚Äî each a standalone production system, together forming a self-improving autonomous intelligence.

### System Architecture

```mermaid
%%{init: {'theme': 'dark', 'themeVariables': { 'primaryColor': '#1a1b27', 'primaryTextColor': '#a9b1d6', 'primaryBorderColor': '#70a5fd', 'lineColor': '#545c7e', 'secondaryColor': '#24283b', 'tertiaryColor': '#1a1b27', 'fontSize': '14px', 'fontFamily': 'JetBrains Mono, monospace' }}}%%

flowchart TD
    KERNEL["<b>UNIFIED SUPERVISOR KERNEL</b><br/>Single Entry Point ¬∑ 50K+ LOC<br/>7-Zone Parallel Initialization"]

    KERNEL -->|"orchestrates"| JARVIS
    KERNEL -->|"routes inference"| PRIME
    KERNEL -->|"triggers training"| REACTOR

    subgraph JARVIS["<b>JARVIS ‚Äî The Body</b> &nbsp; Python / Rust / Swift &nbsp; :8010"]
        direction TB
        J1["üï∏Ô∏è Neural Mesh<br/><i>16+ async agents ¬∑ capability routing</i>"]
        J2["üéôÔ∏è Voice & Auth<br/><i>ECAPA-TDNN ¬∑ full-duplex ¬∑ wake word</i>"]
        J3["üëÅÔ∏è Vision & Spatial<br/><i>LLaVA ¬∑ YOLO ¬∑ Ghost Display ¬∑ OCR</i>"]
        J4["üçé macOS Native<br/><i>Swift 203 files ¬∑ ObjC ¬∑ Rust ¬∑ CoreML</i>"]
        J5["üß† Intelligence<br/><i>RAG ¬∑ Ouroboros ¬∑ Google Workspace</i>"]
    end

    subgraph PRIME["<b>JARVIS-Prime ‚Äî The Mind</b> &nbsp; Python / GGUF &nbsp; :8000-8001"]
        direction TB
        P1["üì° Task-Type Router<br/><i>11 specialist models ¬∑ 40.4 GB</i>"]
        P2["‚ö° Neural Switchboard<br/><i>v98.1 ¬∑ WebSocket contracts</i>"]
        P3["üëÅÔ∏è LLaVA Vision Server<br/><i>multimodal ¬∑ OpenAI-compatible API</i>"]
        P4["üí≠ Reasoning Engine<br/><i>CoT / ToT / self-reflection</i>"]
        P5["üìä Telemetry Capture<br/><i>JSONL ¬∑ deployment feedback loop</i>"]
    end

    subgraph REACTOR["<b>ReactorCore ‚Äî The Forge</b> &nbsp; C++ / Python &nbsp; :8090"]
        direction TB
        R1["üî• Training Pipeline<br/><i>LoRA ¬∑ DPO ¬∑ RLHF ¬∑ FSDP</i>"]
        R2["üö™ Deployment Gate<br/><i>integrity validation ¬∑ probation monitor</i>"]
        R3["üß¨ Model Lineage<br/><i>full provenance chain ¬∑ append-only JSONL</i>"]
        R4["‚òÅÔ∏è GCP Spot Recovery<br/><i>checkpoint persistence ¬∑ 60% cost savings</i>"]
        R5["‚öôÔ∏è C++ Kernels<br/><i>CMake ¬∑ pybind11 ¬∑ native performance</i>"]
    end

    PRIME -.->|"telemetry + experiences"| REACTOR
    REACTOR -.->|"improved GGUF models"| PRIME
    JARVIS <-.->|"inference requests / responses"| PRIME
    REACTOR -.->|"training signals"| JARVIS

    style KERNEL fill:#1a1b27,stroke:#70a5fd,stroke-width:2px,color:#70a5fd
    style JARVIS fill:#0d1117,stroke:#70a5fd,stroke-width:2px,color:#a9b1d6
    style PRIME fill:#0d1117,stroke:#bf91f3,stroke-width:2px,color:#a9b1d6
    style REACTOR fill:#0d1117,stroke:#bb9af7,stroke-width:2px,color:#a9b1d6
```

### Data Flow

```mermaid
%%{init: {'theme': 'dark', 'themeVariables': { 'primaryColor': '#1a1b27', 'primaryTextColor': '#a9b1d6', 'lineColor': '#545c7e', 'fontSize': '13px', 'fontFamily': 'JetBrains Mono, monospace' }}}%%

flowchart LR
    A["üé§ Voice Input"] --> B["JARVIS Kernel"]
    C["üëÅÔ∏è Screen Capture"] --> B
    D["‚å®Ô∏è User Command"] --> B
    B --> E["JARVIS-Prime<br/><i>inference routing</i>"]
    E --> F{"Task Type?"}
    F -->|"math"| G["Qwen2.5-7B"]
    F -->|"code"| H["DeepCoder"]
    F -->|"vision"| I["LLaVA"]
    F -->|"simple"| J["Fast 2.2GB"]
    F -->|"complex"| K["Claude API"]
    G & H & I & J & K --> L["Response"]
    L --> B
    E -->|"telemetry"| M["ReactorCore"]
    M -->|"LoRA/DPO training"| N["Improved Model"]
    N -->|"deploy + probation"| E

    style B fill:#1a1b27,stroke:#70a5fd,stroke-width:2px,color:#70a5fd
    style E fill:#1a1b27,stroke:#bf91f3,stroke-width:2px,color:#bf91f3
    style M fill:#1a1b27,stroke:#bb9af7,stroke-width:2px,color:#bb9af7
    style F fill:#24283b,stroke:#545c7e,stroke-width:1px,color:#a9b1d6
```

### Three-Tier Inference Routing

```mermaid
%%{init: {'theme': 'dark', 'themeVariables': { 'primaryColor': '#1a1b27', 'primaryTextColor': '#a9b1d6', 'lineColor': '#545c7e', 'fontSize': '13px', 'fontFamily': 'JetBrains Mono, monospace' }}}%%

flowchart LR
    REQ["Inference Request"] --> T1
    T1["‚òÅÔ∏è Tier 1: GCP Golden Image<br/><i>11 models ¬∑ ~30s cold start</i>"]
    T1 -->|"unavailable"| T2["üíª Tier 2: Local Apple Silicon<br/><i>M1 Metal GPU ¬∑ on-device</i>"]
    T2 -->|"resource constrained"| T3["üîë Tier 3: Claude API<br/><i>emergency fallback</i>"]
    T1 -->|"‚úÖ success"| RES["Response"]
    T2 -->|"‚úÖ success"| RES
    T3 -->|"‚úÖ success"| RES

    style T1 fill:#1a1b27,stroke:#70a5fd,stroke-width:2px,color:#70a5fd
    style T2 fill:#1a1b27,stroke:#bf91f3,stroke-width:2px,color:#bf91f3
    style T3 fill:#1a1b27,stroke:#bb9af7,stroke-width:2px,color:#bb9af7
    style REQ fill:#24283b,stroke:#545c7e,stroke-width:1px,color:#a9b1d6
    style RES fill:#24283b,stroke:#545c7e,stroke-width:1px,color:#a9b1d6
```

---

<div align="center">

### Repository Breakdown

<table>
<tr>
<td align="center" width="33%">

<a href="https://github.com/drussell23/JARVIS">
<img src="https://img.shields.io/badge/JARVIS-The_Body-70a5fd?style=for-the-badge" />
</a>
<br><br>
<img src="https://skillicons.dev/icons?i=py,rust,swift&theme=dark" width="100"/>
<br><br>
<b>Port 8010</b><br>
60+ Agent Neural Mesh<br>
Voice Biometrics<br>
Ghost Display + Vision<br>
macOS Native (203 Swift files)<br>
RAG + Ouroboros Self-Programming

</td>
<td align="center" width="33%">

<a href="https://github.com/drussell23/JARVIS-Prime">
<img src="https://img.shields.io/badge/JARVIS--Prime-The_Mind-bf91f3?style=for-the-badge" />
</a>
<br><br>
<img src="https://skillicons.dev/icons?i=py,gcp,docker&theme=dark" width="100"/>
<br><br>
<b>Port 8000-8001</b><br>
11 Specialist GGUF Models (40.4 GB)<br>
Task-Type Inference Routing<br>
LLaVA Vision Server<br>
CoT/ToT Reasoning Engine<br>
Neural Switchboard v98.1

</td>
<td align="center" width="33%">

<a href="https://github.com/drussell23/JARVIS-Reactor">
<img src="https://img.shields.io/badge/ReactorCore-The_Forge-bb9af7?style=for-the-badge" />
</a>
<br><br>
<img src="https://skillicons.dev/icons?i=cpp,py,cmake&theme=dark" width="100"/>
<br><br>
<b>Port 8090</b><br>
LoRA / DPO / RLHF Training<br>
Deployment Gate + Probation<br>
Model Lineage Tracking<br>
GCP Spot VM Auto-Recovery<br>
Native C++ Training Kernels

</td>
</tr>
</table>

</div>

---

### <img src="https://img.shields.io/badge/JARVIS-The_Body-70a5fd?style=flat-square" /> &nbsp; Deep Dive

<details>
<summary><b>Agent Architecture</b></summary>
<br>

- **Neural Mesh** ‚Äî 16+ specialized agents (activity recognition, adaptive resource governor, context tracker, error analyzer, goal inference, Google Workspace, health monitor, memory, pattern recognition, predictive planning, spatial awareness, visual monitor, web search, coordinator) with asynchronous message passing, capability-based routing, and cross-agent data flow
- **Autonomous Agent Runtime** ‚Äî multi-step goal decomposition, agentic task execution, tool orchestration, error recovery, and intervention decision engine with human-in-the-loop approval for destructive actions
- **AGI OS Coordinator** ‚Äî proactive event stream, notification bridge, owner identity service, voice approval manager, and intelligent startup announcer

</details>

<details>
<summary><b>Voice and Authentication</b></summary>
<br>

- **Real-time voice biometric authentication** via ECAPA-TDNN speaker verification with cloud/local hybrid inference and multi-factor fusion (voice + proximity + behavioral)
- **Real-time voice conversation** ‚Äî full-duplex audio (simultaneous mic + speaker), acoustic echo cancellation (speexdsp), streaming STT (faster-whisper), adaptive turn detection, barge-in control, and sliding 20-turn context window
- **Wake word detection** (Porcupine/Picovoice), Apple Watch Bluetooth proximity auth, continuous learning voice profiles
- **Unified speech state management** ‚Äî STT hallucination guard, voice pipeline orchestration, parallel model loading

</details>

<details>
<summary><b>Vision and Spatial Intelligence</b></summary>
<br>

- **Never-skip screen capture** ‚Äî two-phase monitoring (always-capture + conditional-analysis), self-hosted LLaVA multimodal analysis, Claude Vision escalation
- **Ghost Display** ‚Äî virtual macOS display for non-intrusive background automation, Ghost Hands orchestrator for autonomous visual workflows
- **Claude Computer Use** ‚Äî automated mouse, keyboard, and screenshot interaction via Anthropic's Computer Use API
- **OCR / OmniParser** ‚Äî screen text extraction, window analysis, workspace name detection, multi-monitor and multi-space intelligence via yabai window manager
- **YOLO + Claude hybrid vision** ‚Äî object detection with LLM-powered semantic understanding
- **Rust vision core** ‚Äî native performance for fast image processing, bloom filter networks, and sliding window analysis

</details>

<details>
<summary><b>macOS Native Integration (Swift / Objective-C / Rust)</b></summary>
<br>

- **Swift bridge** (203 files) ‚Äî CommandClassifier, SystemControl (preferences, security, clipboard, filesystem), PerformanceCore, ScreenCapture, WeatherKit, CoreLocation GPS
- **Objective-C voice unlock daemon** ‚Äî JARVISVoiceAuthenticator, JARVISVoiceMonitor, permission manager, launchd service integration
- **Rust performance layer** ‚Äî PyO3 bindings for memory pool management, quantized ML inference, vision fast processor, command classifier, health predictor; ARM64 SIMD assembly optimizations
- **CoreML acceleration** ‚Äî on-device intent classification, voice processing

</details>

<details>
<summary><b>Infrastructure and Reliability</b></summary>
<br>

- **Parallel initializer** with cooperative cancellation, adaptive EMA-based deadlines, dependency propagation, and atomic state persistence
- **CPU-pressure-aware cloud shifting** ‚Äî automatic workload offload to GCP when local resources are constrained
- **Enterprise hardening** ‚Äî dependency injection container, enterprise process manager, system hardening, governance, Cloud SQL with race-condition-proof proxy management, TLS-safe connection factories, distributed lock manager
- **Three-tier inference routing**: GCP Golden Image (primary) ‚Üí Local Apple Silicon (fallback) ‚Üí Claude API (emergency)
- **Trinity event bus** ‚Äî cross-repo IPC hub, heartbeat publishing, knowledge graph, state management, process coordination
- **Cost tracking and rate limiting** ‚Äî GCP cost optimization with Bayesian confidence fusion, intelligent rate orchestration
- **File integrity guardian** ‚Äî pre-commit integrity verification across the codebase

</details>

<details>
<summary><b>Intelligence and Learning</b></summary>
<br>

- **Google Workspace Agent** ‚Äî Gmail read/search/draft, Google Calendar, natural language intent routing via tiered command router
- **Proactive intelligence** ‚Äî predictive suggestions, proactive vision monitoring, proactive communication, emotional intelligence module
- **RAG pipeline** ‚Äî ChromaDB vector store, FAISS similarity search, embedding service, long-term memory system
- **Chain-of-thought / reasoning graph engine** ‚Äî LangGraph-based multi-step reasoning with conditional routing and reflection loops
- **Ouroboros** ‚Äî self-programming engine for autonomous codebase analysis and improvement
- **Web research service** ‚Äî autonomous web search and information synthesis
- **A/B testing framework** ‚Äî vision pipeline experimentation
- **Repository intelligence** ‚Äî code ownership analysis, dependency analyzer, API contract analyzer, AST transformer, cross-repo refactoring engine

</details>

### <img src="https://img.shields.io/badge/JARVIS--Prime-The_Mind-bf91f3?style=flat-square" /> &nbsp; Deep Dive

<details>
<summary><b>Inference and Routing</b></summary>
<br>

- **11 specialist GGUF models** (~40.4 GB) pre-baked into a GCP golden image with ~30-second cold starts
- **Task-type routing** ‚Äî math queries hit Qwen2.5-7B, code queries hit DeepCoder, simple queries hit a 2.2 GB fast model, vision hits LLaVA
- **GCP Model Swap Coordinator** with intelligent hot-swapping, per-model configuration, and inference validation
- **Neural Switchboard v98.1** ‚Äî stable public API facade over routing and orchestration with WebSocket integration contracts
- **Hollow Client mode** for memory-constrained hardware ‚Äî strict lazy imports, zero ML dependencies at startup on 16 GB machines

</details>

<details>
<summary><b>Reasoning and Telemetry</b></summary>
<br>

- **Continuous learning hook** ‚Äî post-inference experience recording for Elastic Weight Consolidation via ReactorCore
- **Reasoning engine activation** ‚Äî chain-of-thought scaffolding (CoT/ToT/self-reflection) for high-complexity requests above configurable thresholds
- **APARS protocol** (Adaptive Progress-Aware Readiness System) ‚Äî 6-phase startup with real-time health reporting to the supervisor
- **LLaVA vision server** ‚Äî multimodal inference on port 8001 with OpenAI-compatible API, semaphore serialization, queue depth cap
- **Telemetry capture** ‚Äî structured JSONL interaction logging with deployment feedback loop and post-deployment probation monitoring

</details>

### <img src="https://img.shields.io/badge/ReactorCore-The_Forge-bb9af7?style=flat-square" /> &nbsp; Deep Dive

<details>
<summary><b>Training Pipeline</b></summary>
<br>

- **Full training pipeline**: telemetry ingestion ‚Üí active learning selection ‚Üí gatekeeper evaluation ‚Üí LoRA SFT ‚Üí GGUF export ‚Üí deployment gate ‚Üí probation monitoring ‚Üí feedback loop
- **DeploymentGate** validates model integrity before deployment; rejects corrupt or degenerate outputs
- **Post-deployment probation** ‚Äî 30-minute health monitoring window with automatic commit or rollback based on live inference quality
- **Model lineage tracking** ‚Äî full provenance chain (hash, parent model, training method, evaluation scores, gate decision) in append-only JSONL
- **Tier-2/Tier-3 runtime orchestration** ‚Äî curriculum learning, meta-learning (MAML), causal discovery with correlation-based fallback, world model training

</details>

<details>
<summary><b>Infrastructure and Integration</b></summary>
<br>

- **GCP Spot VM auto-recovery** with training checkpoint persistence and 60% cost reduction over on-demand instances
- **Native C++ training kernels** via CMake/pybind11/cpp-httplib for performance-critical operations
- **Atomic experience snapshots** ‚Äî buffer drain under async lock, JSONL with DataHash for dataset versioning
- **PrimeConnector** ‚Äî WebSocket path rotation, health polling fallback, contract path discovery for cross-repo communication
- **Cross-repo integration** ‚Äî Ghost Display state reader, cloud mode detection, Trinity Unified Loop Manager, pipeline event logger with correlation IDs

</details>

---

## Technical Footprint

| Metric | Value |
|--------|-------|
| **Total commits** | 3,900+ across 3 repositories |
| **Codebase** | ~2.5 million lines across 11 languages |
| **Build duration** | 12 months, solo |
| **Unified kernel** | 50,000+ lines in a single orchestration file |
| **Neural Mesh agents** | 16+ specialized agents with async message passing |
| **Models served** | 11 specialist GGUF models via task-type routing |
| **Inference tiers** | GCP Golden Image ‚Üí Local Metal GPU ‚Üí Claude API |
| **Training pipeline** | Automated: telemetry ‚Üí active learning ‚Üí gatekeeper ‚Üí training ‚Üí GGUF export ‚Üí deployment gate ‚Üí probation ‚Üí feedback |
| **Voice auth** | Multi-factor: ECAPA-TDNN biometric + Apple Watch proximity + behavioral analysis |
| **Vision pipeline** | Never-skip capture, LLaVA self-hosted, Claude escalation, YOLO hybrid, OCR/OmniParser |
| **Swift components** | 203 files ‚Äî system control, command classifier, screen capture, GPS, weather |
| **Rust crates** | 5 Cargo workspaces ‚Äî memory pool, vision processor, ML inference, SIMD optimizations |
| **Terraform modules** | 7 modules (compute, network, security, storage, monitoring, budget, Spot templates) |
| **Dockerfiles** | 6 (backend, backend-slim, frontend, training, cloud, GCP inference) |
| **GitHub Actions** | 20+ workflows (CI/CD, CodeQL, e2e testing, deployment, database validation, file integrity) |
| **macOS integration** | Native Swift/ObjC daemons, yabai WM, Ghost Display, multi-space/multi-monitor, launchd services |
| **Cloud infrastructure** | GCP (Compute Engine, Cloud SQL, Cloud Run, Secret Manager, Monitoring), Spot VM auto-recovery |
| **Google Workspace** | Gmail read/search/draft, Calendar, natural language routing via tiered command router |

---

## Background

I graduated from Cal Poly San Luis Obispo with a B.S. in Computer Engineering after a [10-year non-traditional academic path](https://mustangnews.net/10-years-in-the-making-one-cal-poly-students-unique-path-to-an-engineering-degree/) that started in remedial algebra at community college. I retook courses, studied through the loss of family, and spent most of my twenties earning a degree that others finish in four years. The path was not conventional. The outcome was.

JARVIS is what happens when that level of persistence meets engineering capability. Twelve months of daily commits, architectural decisions at every layer of the stack, and a refusal to ship anything that is not production-grade.

---

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/derek-j-russell/)
[![Article](https://img.shields.io/badge/Mustang_News-Read_My_Feature-8B0000?style=for-the-badge)](https://mustangnews.net/10-years-in-the-making-one-cal-poly-students-unique-path-to-an-engineering-degree/)

</div>

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:0d1117,50:1a1b27,100:24283b&height=120&section=footer" width="100%"/>
